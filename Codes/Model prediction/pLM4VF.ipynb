{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c1e7de-4350-4fe7-8a0c-3656c0a0bc55",
   "metadata": {},
   "source": [
    "pLM4VF model for virulence factor prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b6f80-00c2-4d12-a135-f8180582ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def fasta_to_excel(fasta_file, excel_file):\n",
    "    \n",
    "    records = SeqIO.parse(fasta_file, \"fasta\")\n",
    "    \n",
    "    \n",
    "    data = {\"ID\": [], \"Sequence\": []}\n",
    "    for record in records:\n",
    "        protein_name = record.id\n",
    "        sequence = str(record.seq)\n",
    "        data[\"ID\"].append(protein_name)\n",
    "        data[\"Sequence\"].append(sequence)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    \n",
    "    df.to_excel(excel_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5f1e4-a1b4-41a6-92bf-a9dbd61f716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = \"test.fasta\"\n",
    "excel_file = \"test.xlsx\"\n",
    "fasta_to_excel(fasta_file, excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7c2bf7-7f9f-461d-8154-96e9026079b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('test.xlsx',na_filter = False) \n",
    "sequence_list = dataset['Sequence'].apply(lambda x: x[:1000] if len(x) > 1000 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45559300-f4c5-4be1-97d7-465584c55064",
   "metadata": {},
   "source": [
    "Gram positive prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d867abbb-aeed-4d07-a53b-b074a09072dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esm_embeddings(peptide_sequence_list):\n",
    "  import torch\n",
    "  import esm\n",
    "  import pandas as pd\n",
    "  import collections\n",
    "  model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "  batch_converter = alphabet.get_batch_converter()\n",
    "  model.eval()  \n",
    "\n",
    "  embeddings_results = []\n",
    "  for peptide_sequence in peptide_sequence_list:\n",
    "      \n",
    "      batch_labels, batch_strs, batch_tokens = batch_converter([peptide_sequence])\n",
    "      batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "      \n",
    "      with torch.no_grad():\n",
    "          results = model(batch_tokens, repr_layers=[33], return_contacts=True)  \n",
    "      token_representations = results[\"representations\"][33]\n",
    "      sequence_representations = []\n",
    "      for i, tokens_len in enumerate(batch_lens):\n",
    "          sequence_representations.append(token_representations[i, 1:tokens_len-1].mean(0))\n",
    "      \n",
    "      sequence_embeddings = []\n",
    "      for i in range(len(sequence_representations)):\n",
    "          each_seq_rep = sequence_representations[i].tolist()\n",
    "          sequence_embeddings.extend(each_seq_rep)\n",
    "      \n",
    "      embeddings_results.append(sequence_embeddings)\n",
    "  \n",
    "  embeddings_results = pd.DataFrame(embeddings_results)\n",
    "  return embeddings_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaabe8a-f94f-4256-8656-2adb8d4c169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_sequence_list = []\n",
    "for seq in sequence_list:\n",
    "    format_seq = [seq,seq] \n",
    "    tuple_sequence = tuple(format_seq)\n",
    "    peptide_sequence_list.append(tuple_sequence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deabed9-e10d-44d5-b7c7-f676ba633b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_results = esm_embeddings(peptide_sequence_list)\n",
    "embeddings_results.insert(0, 'ID', dataset['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4421d44-7440-45f7-9c23-a311f701ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = joblib.load('pLM4VF(G+)_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c820e369-2230-4b7d-a08e-d6eeb2c10dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = embeddings_results.columns.values.tolist()[1:1281]\n",
    "embeddings_pr = pd.DataFrame(embeddings_results[col])\n",
    "scaler = StandardScaler()\n",
    "predicted_pr = scaler.fit_transform(embeddings_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6af7bc-7156-481d-89e2-44df90549f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(predicted_pr)\n",
    "prediction_results = pd.DataFrame(prediction, columns=['pLM4VF'])\n",
    "prediction_results.insert(0, 'ID', embeddings_results['ID'])\n",
    "predicted_probabilities = model.predict_proba(predicted_pr)\n",
    "prediction_results['Prediction_Scores_0'] = [prob[0] for prob in predicted_probabilities]\n",
    "prediction_results['Prediction_Scores_1'] = [prob[1] for prob in predicted_probabilities]\n",
    "prediction_results.to_csv('pLM4VF_G+.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed21b82d-05fc-4c01-a0c3-05c83bb30072",
   "metadata": {},
   "source": [
    "Gram negative prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bedae7e-5b84-4c65-aac2-9fff70f88e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esm_embeddings(peptide_sequence_list):\n",
    "  import torch\n",
    "  import esm\n",
    "  import pandas as pd\n",
    "  import collections\n",
    "  \n",
    "  model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "  batch_converter = alphabet.get_batch_converter()\n",
    "  model.eval()  \n",
    "\n",
    "  embeddings_results = []\n",
    "  for peptide_sequence in peptide_sequence_list:\n",
    "      \n",
    "      batch_labels, batch_strs, batch_tokens = batch_converter([peptide_sequence])\n",
    "      batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "      \n",
    "      with torch.no_grad():\n",
    "          results = model(batch_tokens, repr_layers=[33], return_contacts=True)  \n",
    "      token_representations = results[\"representations\"][33]\n",
    "      sequence_representations = []\n",
    "      for i, tokens_len in enumerate(batch_lens):\n",
    "          sequence_representations.append(token_representations[i, 1:tokens_len-1].mean(0))\n",
    "      \n",
    "      sequence_embeddings = []\n",
    "      for i in range(len(sequence_representations)):\n",
    "          each_seq_rep = sequence_representations[i].tolist()\n",
    "          sequence_embeddings.extend(each_seq_rep)\n",
    "      \n",
    "      embeddings_results.append(sequence_embeddings)\n",
    "  \n",
    "  embeddings_results = pd.DataFrame(embeddings_results)\n",
    "  return embeddings_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c65e115-0f88-4975-af11-d3293c7bc71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_sequence_list = []\n",
    "for seq in sequence_list:\n",
    "    format_seq = [seq,seq] \n",
    "    tuple_sequence = tuple(format_seq)\n",
    "    peptide_sequence_list.append(tuple_sequence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73156ed2-6b32-4679-8e7e-35529fd66b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_results = esm_embeddings(peptide_sequence_list)\n",
    "embeddings_results.insert(0, 'ID', dataset['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123835e-99de-490a-aa6a-6ef732c9a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = joblib.load('pLM4VF(G-)_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d4bd45-ab8c-410c-991d-07c83de443dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = embeddings_results.columns.values.tolist()[1:1281]\n",
    "embeddings_pr = pd.DataFrame(embeddings_results[col])\n",
    "scaler = StandardScaler()\n",
    "predicted_pr = scaler.fit_transform(embeddings_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd845414-3895-401a-bf03-defe492c3352",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(predicted_pr)\n",
    "prediction_results = pd.DataFrame(prediction, columns=['pLM4VF'])\n",
    "prediction_results.insert(0, 'ID', embeddings_results['ID'])\n",
    "predicted_probabilities = model.predict_proba(predicted_pr)\n",
    "prediction_results['Prediction_Scores_0'] = [prob[0] for prob in predicted_probabilities]\n",
    "prediction_results['Prediction_Scores_1'] = [prob[1] for prob in predicted_probabilities]\n",
    "prediction_results.to_csv('pLM4VF_G-.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
